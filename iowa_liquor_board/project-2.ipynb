{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Getting started\n",
    "\n",
    "Once you've chosen your scenario, download the data from the Iowa website in csv format. Start by loading the data with pandas. You may need to parse the date columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import seaborn.linearmodels as sblm\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import seaborn.linearmodels as sblm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def eda(dataframe):\n",
    "    # This is the EDA function Ritika wrote and showed us. It is wonderful.\n",
    "    print \"Missing Values \\n \\n\", dataframe.isnull().sum(),\"\\n\"\n",
    "    print \"Duplicate Rows \\n\", dataframe.duplicated().sum(),\"\\n\" # Added this\n",
    "    print \"Dataframe Types \\n \\n\", dataframe.dtypes,\"\\n\"\n",
    "    print \"Dataframe Shape \\n\", dataframe.shape,\"\\n\"\n",
    "    print \"Dataframe Describe \\n \\n\", dataframe.describe(include='all'),\"\\n\"\n",
    "    for feature in dataframe: \n",
    "        print feature\n",
    "        print dataframe[feature].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('~/Downloads/Iowa_Liquor_sales_sample_10pct.csv')\n",
    "df.columns=['date','store_number','city','zip','county_number','county','category','category_name','vendor_number','item_number','item_descript','bottle_ml','state_cost','state_retail','bottles_sold','sale','volume_sold_l','volume_sold_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Cleaning the data\n",
    "df['state_cost'].replace('\\$','',regex=True,inplace=True)\n",
    "df['state_retail'].replace('\\$','',regex=True,inplace=True)\n",
    "df['sale'].replace('\\$','',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Chaniging column types\n",
    "df[['state_cost','state_retail','sale']] = df[['state_cost','state_retail','sale']].apply(pd.to_numeric)\n",
    "df[['store_number','vendor_number','item_number',]]=df[['store_number','vendor_number','item_number']].astype(object)\n",
    "df['date']= pd.to_datetime(df['date'], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Adding in some columns that might be useful later on.\n",
    "df['profit']=(df.state_retail-df.state_cost)*df.bottles_sold\n",
    "df['ppb']=(df.state_retail-df.state_cost)\n",
    "df['profit_margin']=(df.ppb/df.state_retail)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Replacing days of week numbers with day names\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "days = {0:'Mon',1:'Tues',2:'Wed',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "Perform some exploratory statistical analysis and make some plots, such as histograms of transaction totals, bottles sold, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Just checking out the 425 dollar bottle, it looks ok\n",
    "df[df.state_cost==425]\n",
    "df[df.item_number==995381].item_descript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looks like a typo \n",
    "df[df.bottles_sold==2508]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(34867,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[(df['county_number'].isnull())&(df['county'].isnull())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Replacing missing category number with name from the ILB website\n",
    "df.loc[df.category ==1022200, 'category_name'] = 'TEQUILA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##creating a function to look for broken zip codes\n",
    "def zip_check(col):\n",
    "    x=0\n",
    "    for code in col:\n",
    "        if str(code).isdigit() == False:\n",
    "           x+=1 \n",
    "    if x == 0:\n",
    "        print \"no bad zip codes\"\n",
    "    else:\n",
    "        print \"check \"+str(x)+\" zip codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_check(df.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##712 is the area code for Dunlap, the proper zip code is 51529.\n",
    "df.replace('712-2',51529,inplace=True)\n",
    "df[df['zip']==51529].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['zip']=df['zip'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['zip']>53000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The Iowa zip codes all begin with numbers between 50 and 52 anything that began with anything above that is \n",
    "##obviously a mistake. The real zipcode is 52601\n",
    "df.zip.replace(56201,52601,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There doesn't seems to be any negative values for any columns were it would be a problem\n",
    "print df[df['sale']<=0].shape\n",
    "print df[df['bottle_ml']<0].shape\n",
    "print df[df['state_cost']<=0].shape\n",
    "print df[df['state_retail']<=0].shape\n",
    "print df[df['bottles_sold']<=0].shape\n",
    "print df[df['volume_sold_l']<=0].shape\n",
    "print df[df['volume_sold_g']<=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Many columns are missing various values in category_name and county which are referenced elesewhere in the data-frame \n",
    "\n",
    "##Creating dictionaries of each category:category_name and county:county_number, and the opposite.\n",
    "a=dict(zip(df.category.unique(),df.category_name.unique()))\n",
    "b=dict(zip(df.category_name.unique(),df.category.unique()))\n",
    "c=dict(zip(df.county_number.unique(),df.county.unique()))\n",
    "d=dict(zip(df.county.unique(),df.county_number.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Referencing any category row that is True for our mask rule, and mapping over them using the dictionaries I created as a\n",
    "#guide for the reference column.\n",
    "mask1 = df.category_name.isnull()\n",
    "mask2 = df.category.isnull()\n",
    "mask3 = df.county.isnull()\n",
    "mask4 = df.county_number.isnull()\n",
    "df.loc[mask1,'category_name'] = df.loc[mask1, 'category'].map(a)\n",
    "df.loc[mask2,'category'] = df.loc[mask2, 'category_name'].map(b)\n",
    "df.loc[mask3,'county'] = df.loc[mask3, 'county_number'].map(c)\n",
    "df.loc[mask4,'county_number'] = df.loc[mask4, 'county'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##I'm going to create a correlation heat map with all of my quantitative data to try to find  parameters to put into the model.\n",
    "num_data=pd.DataFrame(df[['sale','volume_sold_l','bottles_sold','state_cost','state_retail','bottle_ml']],index=None)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_matrix = num_data.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(data_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.heatmap(correlation_matrix,annot = True,linewidths = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record your findings\n",
    "\n",
    "Be sure to write out anything observations from your exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There seems to be a quite obvious correlation between sale amount vs. volume sold in liters, \n",
    "#and sale amount vs. bottles sold. While it may seem like a good thing that we found such a strong paramter \n",
    "#for sale amount the clear lack of independence b/w all the variables, has a negative affect on our data that must be\n",
    "#accounted for, either by dropping it completely or creating an interaction terms. There is a perfect correlation b/w state cost \n",
    "# and state retail, this is because the markup is an even 33% for all categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine the data\n",
    "\n",
    "Now you are ready to compute the variables you will use for your regression from the data. For example, you may want to compute total sales per store from Jan to March of 2015, mean price per bottle, etc. Refer to the readme for more ideas appropriate to your scenario.\n",
    "\n",
    "Pandas is your friend for this task. Take a look at the operations here for ideas on how to make the best use of pandas and feel free to search for blog and Stack Overflow posts to help you group data by certain variables and compute sums, means, etc. You may find it useful to create a new data frame to house this summary data.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Placing all of the sub-data-frames that I'm working with together to remove clutter\n",
    "df15=pd.DataFrame(df[df['date'].dt.year==2015])\n",
    "dfq115=pd.DataFrame(df15[(df15['date'].dt.year==2015)&(df15['date'].dt.month < 4)])\n",
    "dfq23415=df15[df15['date'].dt.month > 3]\n",
    "salesq115=dfq115['sale'].groupby(dfq115.store_number).sum()\n",
    "salesq23415=dfq23415['sale'].groupby(dfq23415.store_number).sum()\n",
    "sales15=df15['sale'].groupby(df15.store_number).sum()\n",
    "salesfull=pd.DataFrame(sales15)\n",
    "salesfull['quarter115_sales']=salesq115\n",
    "dfq116=df[df['date'].dt.year==2016]\n",
    "salesq116=dfq116['sale'].groupby(df.store_number).sum()\n",
    "salesq116=pd.DataFrame(salesq116)\n",
    "salesfull['quarter116_sales']=salesq116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Averages of basic stats for each store\n",
    "df15stats=df15.groupby(['county','store_number']).agg({'state_retail':'mean','profit':'mean','ppb':'mean','volume_sold_l':'mean','bottles_sold':'mean','bottle_ml':'mean','sale':'sum','sale':'mean',})\n",
    "df15stats  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.state_retail.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##this is a break down of each store contained in every city by the sum of sales for the first three months of 2015\n",
    "dfq115.groupby(['county','store_number',dfq115['date'].dt.month]).agg({'sale':['sum']}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salesfull.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The first half of the week seems busier than the second probably because stores want to restock before the weekend\n",
    "df15.groupby('day_of_week').agg({'sale':['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top500=df15.groupby(df15.store_number).sum().nlargest(500,'sale').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##With some help from Roland \n",
    "topsales=df15[[store in top500 for store in df15.store_number]].groupby('store_number').agg(lambda x:x.value_counts().index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topsales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine the data\n",
    "\n",
    "Look for any statistical relationships, correlations, or other relevant properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_dummy=pd.get_dummies(topsales['day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# topsales_dummy['summed_sales']=df15.groupby('store_number').agg({'sale':'sum'}).nlargest(500,'sale')\n",
    "# topsales_dummy.isnull().sum()\n",
    "# X3 = topsales_dummy[]\n",
    "\n",
    "# y3 = topsales_dummy['summed_sales']\n",
    "\n",
    "# model1 = sm.OLS(y3, X3).fit() \n",
    "# predictions_dummy = model.predict(X3)\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = salesfull['quarter115_sales']\n",
    "y = salesfull['sale']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit() \n",
    "predictions15 = model.predict(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X).fit()\n",
    "X2=salesfull['quarter116_sales']\n",
    "X2=sm.add_constant(X2)\n",
    "salesfull['quarter23416']=model.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salesfull['full_2016']=salesfull['quarter23416']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salesfull.head()\n",
    "print salesfull.sale.sum()\n",
    "print salesfull.full_2016.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X_test)\n",
    "print np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridgereg = Ridge(alpha=.1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(predictions15, y, s=30, c='b', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values from Q1\")\n",
    "plt.ylabel(\"Actual Values 2015\")\n",
    "plt.show()\n",
    "print \"MSE:\", model.mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(275784905.11-273425332.18)/273425332.18*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2.3 million projected sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
